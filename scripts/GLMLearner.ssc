import org.apache.spark.rdd.RDD
import scala.reflect.ClassTag
import BIDMat.FMat
import BIDMat.MatIO
import BIDMat.MatFunctions._
import BIDMat.SciFunctions._
import BIDMat.Solvers._
import BIDMach.RunOnSpark._
import BIDMach.RunOnSparkGLM._
import BIDMach.Learner
import BIDMach.models.GLM
import org.apache.hadoop.io.Text
import org.apache.spark.HashPartitioner
import org.apache.spark.storage.StorageLevel

// Specify IP address of master here
val MASTER_DNS = java.net.InetAddress.getLocalHost.getHostAddress
val num_executors = 4

// Run prep_glm_data.ssc to prepare this data
val rdd_data = sc.sequenceFile(
   "hdfs://%s:9000/BIDMach_MNIST/glm_data_merged_400.lz4".format(MASTER_DNS),
   classOf[Text],
   classOf[BIDMat.MatIO]
).partitionBy(new HashPartitioner(num_executors)).persist(StorageLevel.MEMORY_AND_DISK)

val (learner, opts) = GLM.learner()
//opts.useGPU = true; // TODO: CUBLAS errors?
opts.useGPU = false;
opts.featType = 1;
opts.links = 2*iones(10,1);
opts.targets = mkdiag(ones(10,1)) \ zeros(10, 784);
opts.rmask = zeros(1,10) \ ones(1, 784);

opts.batchSize = 500;
opts.npasses = 5;
opts.lrate = 0.001;  // for logistic

def time[R](block: => R): R = {
    val t0 = System.nanoTime()
    val result = block
    val t1 = System.nanoTime()
    println("Elapsed time: " + (t1 - t0)/math.pow(10, 9) + "s")
    result
}
val learners = time {runOnSparkGLM(sc, learner, rdd_data, num_executors)}

println("done training")

val randPartNum = scala.util.Random.nextInt(800)

val data_dir=System.getenv("BIDMACH_DATA_HOME")+"/MNIST8M/parts_fine/"
var test = loadFMat(data_dir+"data%03d.fmat.lz4" format randPartNum)
val tcats = loadFMat(data_dir+"cat_onehot%03d.fmat.lz4" format randPartNum)
val tcat = maxi2(tcats, 1)._2

val nn = learners(0);

val pmodel = new GLM(new GLM.PredOptions());
pmodel.copyFrom(nn.model);
val popts = pmodel.opts.asInstanceOf[GLM.Opts]
popts.targmap = opts.targmap;
popts.links = opts.links;
popts.targets = null
popts.iweight = opts.iweight;
popts.lim = opts.lim;
popts.hashFeatures = opts.hashFeatures;
popts.hashBound1 = opts.hashBound1;
popts.hashBound2 = opts.hashBound2;

val (pp, popts) = GLM.predictor(pmodel, test)
pp.predict

val preds = FMat(pp.preds(0))

val rocs = roc2(preds, tcats, 1-tcats, 100)

println("Training AUCs:\n%s" format ((0 to 9) on mean(rocs)))
